# wandb
project_name: "wandb project name"
log_wandb: True
run_name: "wand id for the run"
# datasets
panel: "/path/to/fragments/panel" # Fragment files for training
panel_validation_frags: "/path/to/fragments"  # Fragment files for validation
panel_validation_vcfs: "path/to/vcf" # VCF files for validation
# training parameters
min_graph_size: 1  # Minimum size of graphs to use for training
max_graph_size: 5000 # Maximum size of graphs to use for training
skip_trivial_graphs: True
skip_singleton_graphs: True
seed: 12345  # Random seed
max_episodes: null  # Maximum number of episodes to run
render: False  # Enables the rendering of the environment
render_view: "weighted_view"  # Controls how the graph is rendered
num_cores_torch: 2  # Number of threads to use for Pytorch
num_cores_validation: 4 # Number of threads to use to parallelize the validation
interval_validate: 1000  # Number of episodes between model validation runs
debug: True
compress: True
# caching parameters
load_components: True
store_components: True
store_indexes: True
# model parameters
pretrained_model: null  # path to pretrained model; null or "path/to/model"
in_dim: num_features # Number of node features fed to the GNN
hidden_dim: [264, 264, 264] # Dimension of the GNN layers
layer_type: gat # Available layers are detailed in graph_models.py
embedding_vars: {} # Possible additional hyperparameters for the layers like the number of attention heads for gat
gamma: 0.98
lr: lr
normalization: False # Normalization of the edge weights by the number of nodes
weight_norm: False # Normalization of the edge weights by an upper bound on the maxcut
fragment_norm: False # Normalization of the edge weights by the number of fragments
features: [dual] # List of features to use, the names are detailed in the constants.py file
clip: False # Clipped and normalized reward
light_logging: True # Less logging for faster training